<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (18) on Thu Feb 09 18:28:27 GMT 2023 -->
<title>jhealy.aicme4j.net</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="dc.created" content="2023-02-09">
<meta name="description" content="declaration: module: atu.aicme4j, package: jhealy.aicme4j.net">
<meta name="generator" content="javadoc/PackageWriterImpl">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../script-dir/jquery-ui.min.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../jquery-ui.overrides.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
<script type="text/javascript" src="../../../../script-dir/jquery-3.5.1.min.js"></script>
<script type="text/javascript" src="../../../../script-dir/jquery-ui.min.js"></script>
</head>
<body class="package-declaration-page">
<script type="text/javascript">var evenRowColor = "even-row-color";
var oddRowColor = "odd-row-color";
var tableTab = "table-tab";
var activeTableTab = "active-table-tab";
var pathtoroot = "../../../../";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar-top"><button id="navbar-toggle-button" aria-controls="navbar-top" aria-expanded="false" aria-label="Toggle navigation links"><span class="nav-bar-toggle-icon"></span><span class="nav-bar-toggle-icon"></span><span class="nav-bar-toggle-icon"></span></button>
<div class="skip-nav"><a href="#skip-navbar-top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar-top-firstrow" class="nav-list" title="Navigation">
<li><a href="../../../module-summary.html">Module</a></li>
<li class="nav-bar-cell1-rev">Package</li>
<li>Class</li>
<li><a href="package-use.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../help-doc.html#package">Help</a></li>
</ul>
<ul class="sub-nav-list-small">
<li>
<p>Package:</p>
<ul>
<li><a href="#package-description">Description</a></li>
<li><a href="#related-package-summary">Related Packages</a></li>
<li><a href="#class-summary">Classes and Interfaces</a></li>
</ul>
</li>
</ul>
</div>
<div class="sub-nav">
<div id="navbar-sub-list">
<ul class="sub-nav-list">
<li>Package:&nbsp;</li>
<li><a href="#package-description">Description</a>&nbsp;|&nbsp;</li>
<li><a href="#related-package-summary">Related Packages</a>&nbsp;|&nbsp;</li>
<li><a href="#class-summary">Classes and Interfaces</a></li>
</ul>
</div>
<div class="nav-list-search"><label for="search-input">SEARCH:</label>
<input type="text" id="search-input" disabled placeholder="Search">
<input type="reset" id="reset-button" disabled value="reset">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip-navbar-top"></span></nav>
</header>
<div class="flex-content">
<main role="main">
<div class="header">
<div class="sub-title"><span class="module-label-in-package">Module</span>&nbsp;<a href="../../../module-summary.html">atu.aicme4j</a></div>
<h1 title="Package jhealy.aicme4j.net" class="title">Package jhealy.aicme4j.net</h1>
</div>
<hr>
<div class="package-signature">package <span class="element-name">jhealy.aicme4j.net</span></div>
<section class="package-description" id="package-description">
<div class="block"><h2>Aicme4j 1.0 - An easy to use feed-forward neural network for Java</h2> 
 This package contains a suite of classes designed to enable the construction and training of a 
 basic feed-forward neural network. Use the <a href="../NetworkBuilder.html" title="interface in jhealy.aicme4j"><code>NetworkBuilder</code></a> interface and 
 <a href="../NetworkBuilderFactory.html" title="class in jhealy.aicme4j"><code>NetworkBuilderFactory</code></a> to build and train an instance of <a href="NeuralNetwork.html" title="class in jhealy.aicme4j.net"><code>NeuralNetwork</code></a>. 
 An example of this is available in the documentation for <a href="../NetworkBuilderFactory.html" title="class in jhealy.aicme4j"><code>NetworkBuilderFactory</code></a>.
 
 <p>A neural network is a mathematical model that attempts to simulate the structure and function of a 
 biological neural network like the human brain. The network consists of highly connected layers
 of nodes called neurons. Each neuron is an elementary information processing unit that receives one 
 or more inputs, does some computation on the input and then propagates the output to one or more 
 neurons in the next layer. Weighted edges connect the nodes of a layer in the network to the nodes 
 in succeeding and preceding layers. The weighted edges store the knowledge of the neural network.
 
 <p><img alt="Neural Network" src="./doc-files/neuron-example.svg"/>
 
 <p>A neuron uses an activation / transfer function to compute its activation level for its inputs and 
 numerical weights. Each neuron receives multiple input values through its incident edges but only 
 ever produces one output that is propagated in full (not split) to all the neurons that it is 
 connected to.
 
 A neural network can be created consisting of a single neuron, but such a network is only capable of
 learning a linearly-separable function. In practice, a neural network consists of at least three layers:

 <ol>
        <li><b>An input layer:</b> accepts inputs from an external environment and redistributes these to all 
     neurons in the hidden layer. The number of nodes in an input layer corresponds to the number of 
     features in a data set (the shape of the data set). This is the same as the number of columns in
     the data set.</li>
  <li><b>One or more hidden layers:</b> neurons in a hidden layer detect features. Neuron weights represent 
  features that are hidden in input patterns. The <em>Universal Approximation Theorem</em> states that 
  a neural network with a single  hidden layer can learn any continuous function for a set of bounded inputs. 
  A continuous function is a function with no gaps or jumps.</li>
  <li><b>An output layer:</b> accepts output values from a hidden layer and establishes output values for 
  the entire neural network. The number of nodes in an output layer corresponds to the number of labels
  or categories for a classification task. For regression, where the purpose of the neural network is to
  predict a numeric value like a stock price or grade point average, a single output node is enough.</li>
 </ol>
 
 <h2>Bias and &theta; Threshold</h2>
 The bias allows the decision boundary to be moved 
 during training and is the same as -&theta; for the activation of a 
 perceptron:
 <ul>
    <li>f(n) = (x<sub>1</sub> * w<sub>1</sub>) + (x<sub>2</sub> * w<sub>2</sub>) + ...(x<sub>i</sub> * w<sub>i</sub>) - &theta; = 0 &nbsp;&nbsp;&nbsp;(1) Activation of a perceptron</li>
    <li>f(n) = (x<sub>1</sub> * w<sub>1</sub>) + (x<sub>2</sub> * w<sub>2</sub>) + ...(x<sub>i</sub> * w<sub>i</sub>) <b>+ bias</b> = 0 &nbsp;&nbsp;&nbsp;(2) Activation of a neuron</li>
 </ul>
 <p>A bias is needed because the threshold value is usually not known <em>a priori</em> 
 and needs to be determined during training. 
 
 <h2>Topography and Weights</h2>
 The number of nodes and layers in a neural network is called the <b>topography</b> of the network. Once 
 this is determined, the neural network must be trained. As shown in the diagram below, a neural network can
 be implemented as a series of <code>double</code> arrays, having single dimensional arrays for each layer and
 two dimensional arrays for the weights between layers. 
 
 <p><img alt="Neural Network" src="./doc-files/neural-net-weights.svg"/>
 
 <p>If there are <em>n</em> nodes in a layer and <em>m</em>
 nodes in the next layer, then each layer will be represented by arrays of size <em>n</em> rows and <em>m</em> 
 columns respectively. Because each node in each layer is connected to all of the nodes in the next layer, the 
 weights of the edges will require a two dimensional <em>n x m</em> array. A <b>bias</b> (shown in red)
 is usually added as an extra row of weights. The initial value of the weights are randomised values,
 typically between -0.5 and 0.5.

 <p>You should keep the following points in mind when designing the topology for a neural network:  

 <ul>
        <li>Neural networks are an example of supervised learning. This means that they must be trained.
 Training a neural network means adjusting the weights between layers to bring the output into line with 
 the external environment.</li>
  <li>Neural network design is typically empirical and the topology depends on the specific problem.</li>
  <li>There is no neural network design methodology for creating a topology that works for a large 
      number of problems.</li>
  <li>It is difficult to interpret the result of a classification, as the neural network cannot explain 
  why it came to a decision.</li>
 </ul></div>
<dl class="notes">
<dt>Since:</dt>
<dd>Aicme4j 1.0</dd>
<dt>Author:</dt>
<dd>Dr. John Healy, ATU.</dd>
</dl>
</section>
<section class="summary">
<ul class="summary-list">
<li>
<div id="related-package-summary">
<div class="caption"><span>Related Packages</span></div>
<div class="summary-table two-column-summary">
<div class="table-header col-first">Package</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color"><a href="../package-summary.html">jhealy.aicme4j</a></div>
<div class="col-last even-row-color">&nbsp;</div>
</div>
</div>
</li>
<li>
<div id="class-summary">
<div class="table-tabs" role="tablist" aria-orientation="horizontal"><button id="class-summary-tab0" role="tab" aria-selected="true" aria-controls="class-summary.tabpanel" tabindex="0" onkeydown="switchTab(event)" onclick="show('class-summary', 'class-summary', 2)" class="active-table-tab">All Classes and Interfaces</button><button id="class-summary-tab2" role="tab" aria-selected="false" aria-controls="class-summary.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('class-summary', 'class-summary-tab2', 2)" class="table-tab">Classes</button><button id="class-summary-tab3" role="tab" aria-selected="false" aria-controls="class-summary.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('class-summary', 'class-summary-tab3', 2)" class="table-tab">Enum Classes</button><button id="class-summary-tab4" role="tab" aria-selected="false" aria-controls="class-summary.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('class-summary', 'class-summary-tab4', 2)" class="table-tab">Record Classes</button></div>
<div id="class-summary.tabpanel" role="tabpanel">
<div class="summary-table two-column-summary" aria-labelledby="class-summary-tab0">
<div class="table-header col-first">Class</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color class-summary class-summary-tab3"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></div>
<div class="col-last even-row-color class-summary class-summary-tab3">
<div class="block">Enum for neural network activation functions.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="Aicme4jUtils.html" title="class in jhealy.aicme4j.net">Aicme4jUtils</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">This class contains various stateless methods for manipulating the <code>double</code> 
 arrays used in the implementation of the neural network.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="BackpropagationTrainer.html" title="class in jhealy.aicme4j.net">BackpropagationTrainer</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">An implementation of the algorithm for training a multi-layer feed-forward 
 neural network described by Bryson and Ho (1969).</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="DefaultNetworkBuilder.html" title="class in jhealy.aicme4j.net">DefaultNetworkBuilder</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">A fluent builder for constructing and training a multi-layer neural network.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab3"><a href="LayerSize.html" title="enum class in jhealy.aicme4j.net">LayerSize</a></div>
<div class="col-last even-row-color class-summary class-summary-tab3">
<div class="block">Enum for the heuristic to use to compute the number of nodes in a
 hidden layer of a neural network based on the sizes of the input and
 the output layers.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab3"><a href="Loss.html" title="enum class in jhealy.aicme4j.net">Loss</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab3">
<div class="block">Enum for neural network loss functions.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="NeuralNetwork.html" title="class in jhealy.aicme4j.net">NeuralNetwork</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">A multi-layer feed-forward neural network that can learn using supervised 
 training.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab4"><a href="NeuralNetwork.Layer.html" title="class in jhealy.aicme4j.net">NeuralNetwork.Layer</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab4">
<div class="block">A representation of a layer in a neural network.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab3"><a href="Output.html" title="enum class in jhealy.aicme4j.net">Output</a></div>
<div class="col-last even-row-color class-summary class-summary-tab3">
<div class="block">Enum for the tranformation to apply to the highest weighted element in
 the output vector of a neural network and can be applied to either
 categorical or numeric data.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab4"><a href="TrainingStatistics.html" title="class in jhealy.aicme4j.net">TrainingStatistics</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab4">
<div class="block">A record of the hyperparameters used for the backpropagation training of a
 neural network.</div>
</div>
</div>
</div>
</div>
</li>
</ul>
</section>
</main>
</div>
</div>
</body>
</html>
