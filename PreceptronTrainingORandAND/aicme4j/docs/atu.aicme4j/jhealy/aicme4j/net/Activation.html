<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (18) on Thu Feb 09 18:28:27 GMT 2023 -->
<title>Activation</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="dc.created" content="2023-02-09">
<meta name="description" content="declaration: module: atu.aicme4j, package: jhealy.aicme4j.net, enum: Activation">
<meta name="generator" content="javadoc/ClassWriterImpl">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../script-dir/jquery-ui.min.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../jquery-ui.overrides.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
<script type="text/javascript" src="../../../../script-dir/jquery-3.5.1.min.js"></script>
<script type="text/javascript" src="../../../../script-dir/jquery-ui.min.js"></script>
</head>
<body class="class-declaration-page">
<script type="text/javascript">var evenRowColor = "even-row-color";
var oddRowColor = "odd-row-color";
var tableTab = "table-tab";
var activeTableTab = "active-table-tab";
var pathtoroot = "../../../../";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar-top"><button id="navbar-toggle-button" aria-controls="navbar-top" aria-expanded="false" aria-label="Toggle navigation links"><span class="nav-bar-toggle-icon"></span><span class="nav-bar-toggle-icon"></span><span class="nav-bar-toggle-icon"></span></button>
<div class="skip-nav"><a href="#skip-navbar-top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar-top-firstrow" class="nav-list" title="Navigation">
<li><a href="../../../module-summary.html">Module</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="nav-bar-cell1-rev">Class</li>
<li><a href="class-use/Activation.html">Use</a></li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../help-doc.html#class">Help</a></li>
</ul>
<ul class="sub-nav-list-small">
<li>
<p>Summary:</p>
<ul>
<li><a href="#nested-class-summary">Nested</a></li>
<li><a href="#enum-constant-summary">Enum Constants</a></li>
<li>Field</li>
<li><a href="#method-summary">Method</a></li>
</ul>
</li>
<li>
<p>Detail:</p>
<ul>
<li><a href="#enum-constant-detail">Enum Constants</a></li>
<li>Field</li>
<li><a href="#method-detail">Method</a></li>
</ul>
</li>
</ul>
</div>
<div class="sub-nav">
<div id="navbar-sub-list">
<ul class="sub-nav-list">
<li>Summary:&nbsp;</li>
<li><a href="#nested-class-summary">Nested</a>&nbsp;|&nbsp;</li>
<li><a href="#enum-constant-summary">Enum Constants</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#method-summary">Method</a></li>
</ul>
<ul class="sub-nav-list">
<li>Detail:&nbsp;</li>
<li><a href="#enum-constant-detail">Enum Constants</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#method-detail">Method</a></li>
</ul>
</div>
<div class="nav-list-search"><label for="search-input">SEARCH:</label>
<input type="text" id="search-input" disabled placeholder="Search">
<input type="reset" id="reset-button" disabled value="reset">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip-navbar-top"></span></nav>
</header>
<div class="flex-content">
<main role="main">
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="sub-title"><span class="module-label-in-type">Module</span>&nbsp;<a href="../../../module-summary.html">atu.aicme4j</a></div>
<div class="sub-title"><span class="package-label-in-type">Package</span>&nbsp;<a href="package-summary.html">jhealy.aicme4j.net</a></div>
<h1 title="Enum Class Activation" class="title">Enum Class Activation</h1>
</div>
<div class="inheritance" title="Inheritance Tree"><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">java.lang.Object</a>
<div class="inheritance"><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html" title="class or interface in java.lang" class="external-link">java.lang.Enum</a>&lt;<a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a>&gt;
<div class="inheritance">jhealy.aicme4j.net.Activation</div>
</div>
</div>
<section class="class-description" id="class-description">
<dl class="notes">
<dt>All Implemented Interfaces:</dt>
<dd><code><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/io/Serializable.html" title="class or interface in java.io" class="external-link">Serializable</a></code>, <code><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Comparable.html" title="class or interface in java.lang" class="external-link">Comparable</a>&lt;<a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a>&gt;</code>, <code><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/constant/Constable.html" title="class or interface in java.lang.constant" class="external-link">Constable</a></code></dd>
</dl>
<hr>
<div class="type-signature"><span class="modifiers">public enum </span><span class="element-name type-name-label">Activation</span>
<span class="extends-implements">extends <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html" title="class or interface in java.lang" class="external-link">Enum</a>&lt;<a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a>&gt;</span></div>
<div class="block">Enum for neural network activation functions. An activation function is applied to the
 weighted sum of the inputs for each node in a neural network. Depending on the input values, 
 a neuron will fire (activate) and produce an output value for the node called <i>y</i>. 
 <p>
 
 An activation function is also called a transfer function and maps a value <i>x</i> from
 a domain to exactly one value <i>y</i> from the codomain of the function. Activation
 functions can be categorised as either hard or soft limiters.  
 
 <ul>
                <li><b>Hard Limiters:</b> Have a threshold value that results in a sudden state change 
             once the threshold is reached. For example, both the <a href="#STEP"><code>STEP</code></a> and Sign
             functions will switch between -1 / 0 and +1 once a threshold is reached.</li>
             
                <li><b>Soft Limiters:</b> Provide a more graduated and subtle change without any sudden
             state changes. Soft limiters can be divided into linear and non-linear functions.
             Example of linear functions include the <a href="#IDENTITY"><code>IDENTITY</code></a> function. Common soft 
             limiters include the <a href="#SIGMOID"><code>SIGMOID</code></a> and <a href="#TANH"><code>TANH</code></a> transfer functions.</li> 
 </ul>
 <p>
 
 Each function will transform an input value <em>n</em> into a value between a minimum and maximum
 value specific for that function. Each layer in a neural network can be configured with a 
 different activation function. A <a href="#SIGMOID"><code>SIGMOID</code></a> function is ideal for binary classification tasks
 and <a href="#TANH"><code>TANH</code></a> is a good choice as a general purpose transfer function. Functions from the 
 <a href="#RELU"><code>RELU</code></a> family are often used for input and output layers.   
 <p>
 
 Depending on the values used for input and activation function chosen, the input vector 
 to a neural network may have to be normalized (squashed). Functions such as <a href="#SIGMOID"><code>SIGMOID</code></a> 
 and <a href="#TANH"><code>TANH</code></a> can saturate if applied to large or small values. This means that large
 value will map to 1 and small values to 0 or -1 for <a href="#SIGMOID"><code>SIGMOID</code></a> and <a href="#TANH"><code>TANH</code></a>
 respectively. Both of these functions are optimal to changes around their midpoints, 
 0.5 for <a href="#SIGMOID"><code>SIGMOID</code></a> and 0.0 for <a href="#TANH"><code>TANH</code></a>. Part of the design work for a neural
 network is to determine the correct topology, activation function and degree of 
 normalisation required, if any. The utility class <a href="Aicme4jUtils.html" title="class in jhealy.aicme4j.net"><code>Aicme4jUtils</code></a> contains methods for
 squashing the training, testing and live data between the maximum and minimum values that
 are applicable to a specific activation function.
 <p>
 
 An activation function must have a corresponding derivative function that can be used by the
 backpropagation training algorithm. The derivative of a function is its slope and this is
 used to compute the rate of change of the gradient descent during training. Not all activation
 functions are differentiable. A differentiable function must be continuous, i.e. there must be
 a continuous mapping of values from <em>x</em> to <em>y</em> with no discontinuities (gaps or 
 jumps). For example <a href="#STEP"><code>STEP</code></a> and Sign functions contain jumps and do not have 
 derivatives, but have been configured below with the derivatives of <a href="#TANH"><code>TANH</code></a> and <a href="#SIGMOID"><code>SIGMOID</code></a> 
 respectively to approximate a differentiable function.  
 <p>
 
 The backpropagation training algorithm can suffer from a vanishing gradient or exploding
 gradient problem. A vanishing gradient is a change to the gradient of a function that is
 so small that it prevents a weight from changing its value, resulting in a neural network
 that cannot be trained. An exploding gradient is a large error gradient that causes a 
 very large change to weights during training and will also result in the model being unable
 to be trained. The <a href="#RELU"><code>RELU</code></a> function is particularly prone to vanishing and exploding
 gradients. From a practical point of view, this will result in overflow or underflow of the
 <code>double</code> types used to store the weights and cause <code>NaN</code> exceptions. 
 <p>
 
 Beginners should start by using <a href="#SIGMOID"><code>SIGMOID</code></a> for binary classifiers and the <a href="#TANH"><code>TANH</code></a> 
 activation function for multi-class predictions. 
 
 <h2>Summary of Available Activation Functions</h2>
 <table>
 <caption>Activation Functions in this API</caption>
 <tr>
  <th><b>Function Name</b></th>
  <th><b>Graph</b></th>
  <th><b>Equation</b></th>
  <th><b>Derivative</b></th>
 </tr>
 
 <tr>
  <td><b>Arctan</b></td>
  <td><img alt="Arctan" src="./doc-files/garctan.png" width="200" height="200"/></td>
  <td><img alt="Arctan" src="./doc-files/arctan.png" height="30"/></td>
  <td><img alt="Arctan" src="./doc-files/arctan-der.png" height="60"/></td>
 </tr>
 
 <tr>
  <td><b>ELU</b></td>
  <td><img alt="ELU" src="./doc-files/gelu.png" width="200" height="200"/></td>
  <td><img alt="ELU" src="./doc-files/elu.png" height="60"/></td>
  <td><img alt="ELU" src="./doc-files/elu-der.png" height="60"/></td>
 </tr>
 
 <tr>
  <td><b>Gaussian</b></td>
  <td><img alt="ELU" src="./doc-files/ggaussian.png" width="200" height="200"/></td>
  <td><img alt="ELU" src="./doc-files/gaussian.png" height="40"/></td>
  <td><img alt="ELU" src="./doc-files/gaussian-der.png" height="40"/></td>
 </tr> 
  
 <tr>
  <td><b>Identity / Linear</b></td>
  <td><img alt="Identity" src="./doc-files/gidentity.png" width="200" height="200"/></td>
  <td><img alt="Identity" src="./doc-files/identity.png" height="30"/></td>
  <td><img alt="Identity" src="./doc-files/identity-der.png" height="30"/></td>
 </tr>
 
 <tr>
  <td><b>ISRLU</b></td>
  <td><img alt="Inverse Square Root Linear Unit" src="./doc-files/gisrlu.png" width="200" height="200"/></td>
  <td><img alt="Inverse Square Root Linear Unit" src="./doc-files/isrlu.png" height="80"/></td>
  <td><img alt="Inverse Square Root Linear Unit" src="./doc-files/isrlu-der.png" height="80"/></td>
 </tr>
 
 <tr>
  <td><b>ISRU</b></td>
  <td><img alt="Inverse Square Root Unit" src="./doc-files/gisru.png" width="200" height="200"/></td>
  <td><img alt="Inverse Square Root Unit" src="./doc-files/isru.png" height="70"/></td>
  <td><img alt="Inverse Square Root Unit" src="./doc-files/isru-der.png" height="70"/></td>
 </tr>
 
 <tr>
  <td><b>Log-Sigmoid</b></td>
  <td><img alt="Leaky ReLU" src="./doc-files/glogsig.png" width="200" height="200"/></td>
  <td><img alt="Leaky ReLU" src="./doc-files/log-sigmoid.png" height="60"/></td>
  <td><img alt="Leaky ReLU" src="./doc-files/log-sigmoid-der.png" height="60"/></td>
 </tr>
 
 <tr>
  <td><b>Leaky ReLU</b></td>
  <td><img alt="Leaky ReLU" src="./doc-files/gleaky_relu.png" width="200" height="200"/></td>
  <td><img alt="Leaky ReLU" src="./doc-files/PReLU.png" height="60"/></td>
  <td><img alt="Leaky ReLU" src="./doc-files/PReLU-der.png" height="60"/></td>
 </tr>
 
 <tr>
  <td><b>ReLU</b></td>
  <td><img alt="ReLU" src="./doc-files/grelu.png" width="200" height="200"/></td>
  <td><img alt="ReLU" src="./doc-files/ReLU.png" height="60"/></td>
  <td><img alt="ReLU" src="./doc-files/ReLU-der.png" height="60"/></td>
 </tr>
 
 
 <tr>
  <td><b>SELU</b></td>
  <td><img alt="ReLU" src="./doc-files/gselu.png" width="200" height="200"/></td>
  <td><img alt="ReLU" src="./doc-files/selu.png" height="80"/></td>
  <td><img alt="ReLU" src="./doc-files/selu-der.png" height="80"/></td>
 </tr>
 
 <tr>
  <td><b>Sigmoid</b></td>
  <td><img alt="Sigmoid" src="./doc-files/gsigmoid.png" width="200" height="200"/></td>
  <td><img alt="Sigmoid" src="./doc-files/sigmoid.png" height="60"/></td>
  <td><img alt="Sigmoid" src="./doc-files/sigmoid-der.png" height="30"/></td>
 </tr>
 
 <tr>
  <td><b>Sinc</b></td>
  <td><img alt="Sinc" src="./doc-files/gsinc.png" width="200" height="200"/></td>
  <td><img alt="Sinc" src="./doc-files/sinc.png" height="80"/></td>
  <td><img alt="Sinc" src="./doc-files/sinc-der.png" height="80"/></td>
 </tr>
 
 <tr>
  <td><b>Softplus</b></td>
  <td><img alt="Softplus" src="./doc-files/gsoftplus.png" width="200" height="200"/></td>
  <td><img alt="Softplus" src="./doc-files/softplus.png" height="30"/></td>
  <td><img alt="Softplus" src="./doc-files/softplus-der.png" height="60"/></td>
 </tr>

 <tr>
  <td><b>Softsign</b></td>
  <td><img alt="Softsign" src="./doc-files/gsoftsign.png" width="200" height="200"/></td>
  <td><img alt="Softsign" src="./doc-files/softsign.png" height="60"/></td>
  <td><img alt="Softsign" src="./doc-files/softsign-der.png" height="60"/></td>
 </tr>

 <tr>
  <td><b>Step</b></td>
  <td><img alt="Step" src="./doc-files/gstep.png" width="200" height="200"/></td>
  <td><img alt="Step" src="./doc-files/step.png" height="60"/></td>
  <td><img alt="Step" src="./doc-files/step-der.png" height="60"/></td>
 </tr>
 
 <tr>
  <td><b>Swish</b></td>
  <td><img alt="Swish" src="./doc-files/gswish.png" width="200" height="200"/></td>
  <td><img alt="Swish" src="./doc-files/swish.png" height="60"/></td>
  <td><img alt="Swish" src="./doc-files/swish-der.png" height="30"/></td>
 </tr>
 
 <tr>
  <td><b>Tanh</b></td>
  <td><img alt="Tanh" src="./doc-files/gtanh.png" width="200" height="200"/></td>
  <td><img alt="Tanh" src="./doc-files/tanh.png" height="60"/></td>
  <td><img alt="Tanh" src="./doc-files/tanh-der.png" height="30"/></td>
 </tr>
 
 <tr>
  <td><b>TanSig</b></td>
  <td><img alt="TanSig" src="./doc-files/gtansig.png" width="200" height="200"/></td>
  <td><img alt="TanSig" src="./doc-files/tansig.png" height="60"/></td>
  <td><img alt="TanSig" src="./doc-files/tansig-der.png" height="30"/></td>
 </tr>
 
 </table></div>
<dl class="notes">
<dt>Since:</dt>
<dd>Aicme4j 1.0</dd>
<dt>Author:</dt>
<dd>Dr. John Healy, ATU.</dd>
</dl>
</section>
<section class="summary">
<ul class="summary-list">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<li>
<section class="nested-class-summary" id="nested-class-summary">
<h2>Nested Class Summary</h2>
<div class="inherited-list">
<h2 id="nested-classes-inherited-from-class-java.lang.Enum">Nested classes/interfaces inherited from class&nbsp;java.lang.<a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html" title="class or interface in java.lang" class="external-link">Enum</a></h2>
<code><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.EnumDesc.html" title="class or interface in java.lang" class="external-link">Enum.EnumDesc</a>&lt;<a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.EnumDesc.html" title="class or interface in java.lang" class="external-link">E</a> extends <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html" title="class or interface in java.lang" class="external-link">Enum</a>&lt;<a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.EnumDesc.html" title="class or interface in java.lang" class="external-link">E</a>&gt;&gt;</code></div>
</section>
</li>
<!-- =========== ENUM CONSTANT SUMMARY =========== -->
<li>
<section class="constants-summary" id="enum-constant-summary">
<h2>Enum Constant Summary</h2>
<div class="caption"><span>Enum Constants</span></div>
<div class="summary-table two-column-summary">
<div class="table-header col-first">Enum Constant</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color"><code><a href="#ARCTAN" class="member-name-link">ARCTAN</a></code></div>
<div class="col-last even-row-color">
<div class="block">Inverse Tangent is an alternative to hyperbolic tangent and sigmoid that 
 transforms n into a value in the range [−π/2..π/2]</div>
</div>
<div class="col-first odd-row-color"><code><a href="#ELU" class="member-name-link">ELU</a></code></div>
<div class="col-last odd-row-color">
<div class="block">Exponential Linear Unit is faster to train than ReLU.</div>
</div>
<div class="col-first even-row-color"><code><a href="#GAUSSIAN" class="member-name-link">GAUSSIAN</a></code></div>
<div class="col-last even-row-color">
<div class="block">A bell shaped curve useful for modeling Gaussian distributed random variables.</div>
</div>
<div class="col-first odd-row-color"><code><a href="#IDENTITY" class="member-name-link">IDENTITY</a></code></div>
<div class="col-last odd-row-color">
<div class="block">The default activation for an input layer.</div>
</div>
<div class="col-first even-row-color"><code><a href="#ISRLU" class="member-name-link">ISRLU</a></code></div>
<div class="col-last even-row-color">
<div class="block">An alternative to ELU (Exponential Linear Unit) that can be
 faster on some systems where am inverse square root can be 
 computed more efficiently than an exponent.</div>
</div>
<div class="col-first odd-row-color"><code><a href="#ISRU" class="member-name-link">ISRU</a></code></div>
<div class="col-last odd-row-color">
<div class="block">An alternative to tanh.</div>
</div>
<div class="col-first even-row-color"><code><a href="#LEAKY_RELU" class="member-name-link">LEAKY_RELU</a></code></div>
<div class="col-last even-row-color">
<div class="block">Leaky Rectified Linear Unit</div>
</div>
<div class="col-first odd-row-color"><code><a href="#LINEAR" class="member-name-link">LINEAR</a></code></div>
<div class="col-last odd-row-color">
<div class="block">The default activation for an input layer.</div>
</div>
<div class="col-first even-row-color"><code><a href="#LOGSIG" class="member-name-link">LOGSIG</a></code></div>
<div class="col-last even-row-color">
<div class="block">Log-Sigmoid transforms n into a value between -infinity and 0</div>
</div>
<div class="col-first odd-row-color"><code><a href="#RELU" class="member-name-link">RELU</a></code></div>
<div class="col-last odd-row-color">
<div class="block">Rectified Linear Unit transforms n into a value into either 0 or n</div>
</div>
<div class="col-first even-row-color"><code><a href="#SELU" class="member-name-link">SELU</a></code></div>
<div class="col-last even-row-color">
<div class="block">Multiplies the function by a scaling constant &lambda; &gt; 1 to 
 ensure a slope greater than 1 for positive inputs.</div>
</div>
<div class="col-first odd-row-color"><code><a href="#SIGMOID" class="member-name-link">SIGMOID</a></code></div>
<div class="col-last odd-row-color">
<div class="block">Sigmodial transforms n into a value between 0 and 1</div>
</div>
<div class="col-first even-row-color"><code><a href="#SINC" class="member-name-link">SINC</a></code></div>
<div class="col-last even-row-color">
<div class="block">Cardinal Sine, similar to cosine function, n decreases relative to the distance from the 
 origin.</div>
</div>
<div class="col-first odd-row-color"><code><a href="#SOFTPLUS" class="member-name-link">SOFTPLUS</a></code></div>
<div class="col-last odd-row-color">
<div class="block">A smooth version of ReLU that transforms n into a value between from 0 to n</div>
</div>
<div class="col-first even-row-color"><code><a href="#SOFTSIGN" class="member-name-link">SOFTSIGN</a></code></div>
<div class="col-last even-row-color">
<div class="block">An alternative to hyperbolic tangent that transforms n into a value between -1 and 1</div>
</div>
<div class="col-first odd-row-color"><code><a href="#STEP" class="member-name-link">STEP</a></code></div>
<div class="col-last odd-row-color">
<div class="block">Transforms n into either 0 or 1.</div>
</div>
<div class="col-first even-row-color"><code><a href="#SWISH" class="member-name-link">SWISH</a></code></div>
<div class="col-last even-row-color">
<div class="block">An alternative to ReLU, Swish transforms n into a value between -0.5 and n</div>
</div>
<div class="col-first odd-row-color"><code><a href="#TANH" class="member-name-link">TANH</a></code></div>
<div class="col-last odd-row-color">
<div class="block">Hyperbolic Tangent transforms n into a value between -1 and 1</div>
</div>
<div class="col-first even-row-color"><code><a href="#TANSIG" class="member-name-link">TANSIG</a></code></div>
<div class="col-last even-row-color">
<div class="block">Hyperbolic Tangent Sigmoid transforms n into a value between -1 and 1</div>
</div>
</div>
</section>
</li>
<!-- ========== METHOD SUMMARY =========== -->
<li>
<section class="method-summary" id="method-summary">
<h2>Method Summary</h2>
<div id="method-summary-table">
<div class="table-tabs" role="tablist" aria-orientation="horizontal"><button id="method-summary-table-tab0" role="tab" aria-selected="true" aria-controls="method-summary-table.tabpanel" tabindex="0" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table', 3)" class="active-table-tab">All Methods</button><button id="method-summary-table-tab1" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab1', 3)" class="table-tab">Static Methods</button><button id="method-summary-table-tab2" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab2', 3)" class="table-tab">Instance Methods</button><button id="method-summary-table-tab4" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab4', 3)" class="table-tab">Concrete Methods</button></div>
<div id="method-summary-table.tabpanel" role="tabpanel">
<div class="summary-table three-column-summary" aria-labelledby="method-summary-table-tab0">
<div class="table-header col-first">Modifier and Type</div>
<div class="table-header col-second">Method</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>double</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#apply(double,boolean)" class="member-name-link">apply</a><wbr>(double&nbsp;val,
 boolean&nbsp;derivative)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the result of applying either the function or its derivative to val.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#getFullName()" class="member-name-link">getFullName</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the long name of the activation function.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#initialise(java.util.Optional)" class="member-name-link">initialise</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/util/Optional.html" title="class or interface in java.util" class="external-link">Optional</a>&lt;double[][]&gt;&nbsp;matrix)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Initialises the weights of each layer in the neural network depending on the type
 of activation function used.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static <a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#valueOf(java.lang.String)" class="member-name-link">valueOf</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;name)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">
<div class="block">Returns the enum constant of this class with the specified name.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static <a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a>[]</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#values()" class="member-name-link">values</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">
<div class="block">Returns an array containing the constants of this enum class, in
the order they are declared.</div>
</div>
</div>
</div>
</div>
<div class="inherited-list">
<h3 id="methods-inherited-from-class-java.lang.Enum">Methods inherited from class&nbsp;java.lang.<a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html" title="class or interface in java.lang" class="external-link">Enum</a></h3>
<code><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html#clone()" title="class or interface in java.lang" class="external-link">clone</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html#compareTo(E)" title="class or interface in java.lang" class="external-link">compareTo</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html#describeConstable()" title="class or interface in java.lang" class="external-link">describeConstable</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html#equals(java.lang.Object)" title="class or interface in java.lang" class="external-link">equals</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html#finalize()" title="class or interface in java.lang" class="external-link">finalize</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html#getDeclaringClass()" title="class or interface in java.lang" class="external-link">getDeclaringClass</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html#hashCode()" title="class or interface in java.lang" class="external-link">hashCode</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html#name()" title="class or interface in java.lang" class="external-link">name</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html#ordinal()" title="class or interface in java.lang" class="external-link">ordinal</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html#toString()" title="class or interface in java.lang" class="external-link">toString</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Enum.html#valueOf(java.lang.Class,java.lang.String)" title="class or interface in java.lang" class="external-link">valueOf</a></code></div>
<div class="inherited-list">
<h3 id="methods-inherited-from-class-java.lang.Object">Methods inherited from class&nbsp;java.lang.<a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></h3>
<code><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Object.html#getClass()" title="class or interface in java.lang" class="external-link">getClass</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Object.html#notify()" title="class or interface in java.lang" class="external-link">notify</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Object.html#notifyAll()" title="class or interface in java.lang" class="external-link">notifyAll</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Object.html#wait()" title="class or interface in java.lang" class="external-link">wait</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Object.html#wait(long)" title="class or interface in java.lang" class="external-link">wait</a>, <a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/Object.html#wait(long,int)" title="class or interface in java.lang" class="external-link">wait</a></code></div>
</section>
</li>
</ul>
</section>
<section class="details">
<ul class="details-list">
<!-- ============ ENUM CONSTANT DETAIL =========== -->
<li>
<section class="constant-details" id="enum-constant-detail">
<h2>Enum Constant Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="ARCTAN">
<h3>ARCTAN</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">ARCTAN</span></div>
<div class="block">Inverse Tangent is an alternative to hyperbolic tangent and sigmoid that 
 transforms n into a value in the range [−π/2..π/2]</div>
</section>
</li>
<li>
<section class="detail" id="ELU">
<h3>ELU</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">ELU</span></div>
<div class="block">Exponential Linear Unit is faster to train than ReLU. A required alpha parameter 
 is set to 1. ELU transforms n into a value between -1 and n.</div>
</section>
</li>
<li>
<section class="detail" id="SELU">
<h3>SELU</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">SELU</span></div>
<div class="block">Multiplies the function by a scaling constant &lambda; &gt; 1 to 
 ensure a slope greater than 1 for positive inputs. The default
 value for &lambda; and &alpha; are 1.0507 and 1.67326 respectively.</div>
</section>
</li>
<li>
<section class="detail" id="GAUSSIAN">
<h3>GAUSSIAN</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">GAUSSIAN</span></div>
<div class="block">A bell shaped curve useful for modeling Gaussian distributed random variables. The 
 Gaussian is similar to a sigmoidal / logistic activation function but is slower 
 to compute.</div>
</section>
</li>
<li>
<section class="detail" id="ISRLU">
<h3>ISRLU</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">ISRLU</span></div>
<div class="block">An alternative to ELU (Exponential Linear Unit) that can be
 faster on some systems where am inverse square root can be 
 computed more efficiently than an exponent. The default value of 
 alpha is set to 1.</div>
</section>
</li>
<li>
<section class="detail" id="ISRU">
<h3>ISRU</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">ISRU</span></div>
<div class="block">An alternative to tanh. ISRU can be more efficient than tanh and 
 sigmoid when properly shifted and scaled. The default value of 
 alpha is set to 1.</div>
</section>
</li>
<li>
<section class="detail" id="LEAKY_RELU">
<h3>LEAKY_RELU</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">LEAKY_RELU</span></div>
<div class="block">Leaky Rectified Linear Unit</div>
</section>
</li>
<li>
<section class="detail" id="LINEAR">
<h3>LINEAR</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">LINEAR</span></div>
<div class="block">The default activation for an input layer. The The derivative of the identity 
 function is a constant and is independent of the input value. As the slope
 is constant, the identity function cannot be used with backpropagation 
 training.</div>
</section>
</li>
<li>
<section class="detail" id="IDENTITY">
<h3>IDENTITY</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">IDENTITY</span></div>
<div class="block">The default activation for an input layer. The The derivative of the identity 
 function is a constant and is independent of the input value. As the slope
 is constant, the identity function cannot be used with backpropagation 
 training.</div>
</section>
</li>
<li>
<section class="detail" id="RELU">
<h3>RELU</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">RELU</span></div>
<div class="block">Rectified Linear Unit transforms n into a value into either 0 or n</div>
</section>
</li>
<li>
<section class="detail" id="SIGMOID">
<h3>SIGMOID</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">SIGMOID</span></div>
<div class="block">Sigmodial transforms n into a value between 0 and 1</div>
</section>
</li>
<li>
<section class="detail" id="LOGSIG">
<h3>LOGSIG</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">LOGSIG</span></div>
<div class="block">Log-Sigmoid transforms n into a value between -infinity and 0</div>
</section>
</li>
<li>
<section class="detail" id="SINC">
<h3>SINC</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">SINC</span></div>
<div class="block">Cardinal Sine, similar to cosine function, n decreases relative to the distance from the 
 origin. Transforms n into a value between -0.5 and 1.</div>
</section>
</li>
<li>
<section class="detail" id="SOFTPLUS">
<h3>SOFTPLUS</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">SOFTPLUS</span></div>
<div class="block">A smooth version of ReLU that transforms n into a value between from 0 to n</div>
</section>
</li>
<li>
<section class="detail" id="SOFTSIGN">
<h3>SOFTSIGN</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">SOFTSIGN</span></div>
<div class="block">An alternative to hyperbolic tangent that transforms n into a value between -1 and 1</div>
</section>
</li>
<li>
<section class="detail" id="STEP">
<h3>STEP</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">STEP</span></div>
<div class="block">Transforms n into either 0 or 1. The step function only supports a binary 
 classification and cannot be used for a multi-class system. The step function
 is also not differentiable, as it has a slope of 0 everywhere except at 0. This
 means that STEP cannot be used with a backpropagation algorithm as it will not
 be able to apply the delta rule to update the weights.</div>
</section>
</li>
<li>
<section class="detail" id="SWISH">
<h3>SWISH</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">SWISH</span></div>
<div class="block">An alternative to ReLU, Swish transforms n into a value between -0.5 and n</div>
</section>
</li>
<li>
<section class="detail" id="TANH">
<h3>TANH</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">TANH</span></div>
<div class="block">Hyperbolic Tangent transforms n into a value between -1 and 1</div>
</section>
</li>
<li>
<section class="detail" id="TANSIG">
<h3>TANSIG</h3>
<div class="member-signature"><span class="modifiers">public static final</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">TANSIG</span></div>
<div class="block">Hyperbolic Tangent Sigmoid transforms n into a value between -1 and 1</div>
</section>
</li>
</ul>
</section>
</li>
<!-- ============ METHOD DETAIL ========== -->
<li>
<section class="method-details" id="method-detail">
<h2>Method Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="values()">
<h3>values</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a>[]</span>&nbsp;<span class="element-name">values</span>()</div>
<div class="block">Returns an array containing the constants of this enum class, in
the order they are declared.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>an array containing the constants of this enum class, in the order they are declared</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="valueOf(java.lang.String)">
<h3>valueOf</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type"><a href="Activation.html" title="enum class in jhealy.aicme4j.net">Activation</a></span>&nbsp;<span class="element-name">valueOf</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;name)</span></div>
<div class="block">Returns the enum constant of this class with the specified name.
The string must match <i>exactly</i> an identifier used to declare an
enum constant in this class.  (Extraneous whitespace characters are 
not permitted.)</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>name</code> - the name of the enum constant to be returned.</dd>
<dt>Returns:</dt>
<dd>the enum constant with the specified name</dd>
<dt>Throws:</dt>
<dd><code><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/IllegalArgumentException.html" title="class or interface in java.lang" class="external-link">IllegalArgumentException</a></code> - if this enum class has no constant with the specified name</dd>
<dd><code><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/NullPointerException.html" title="class or interface in java.lang" class="external-link">NullPointerException</a></code> - if the argument is null</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="getFullName()">
<h3>getFullName</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a></span>&nbsp;<span class="element-name">getFullName</span>()</div>
<div class="block">Returns the long name of the activation function.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>the full function name.</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="apply(double,boolean)">
<h3>apply</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">double</span>&nbsp;<span class="element-name">apply</span><wbr><span class="parameters">(double&nbsp;val,
 boolean&nbsp;derivative)</span></div>
<div class="block">Returns the result of applying either the function or its derivative to val.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>val</code> - the weighted sum of the inputs to a node in a neural network</dd>
<dd><code>derivative</code> - use the derivative of the function for backpropagation training.</dd>
<dt>Returns:</dt>
<dd>the result of applying either the function or its derivative</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="initialise(java.util.Optional)">
<h3>initialise</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">initialise</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/util/Optional.html" title="class or interface in java.util" class="external-link">Optional</a>&lt;double[][]&gt;&nbsp;matrix)</span></div>
<div class="block">Initialises the weights of each layer in the neural network depending on the type
 of activation function used. Sigmodial, Hyperbolic Tangent and related functions
 are initialised using the Xavier method. The weights of edges to nodes that use the
 Rectified Linear Unit and related transfer functions are initialised using the He
 method. Gaussian, Log-Sigmoid and other functions are initialised using values in 
 the range of {-0.3...0.3].</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>matrix</code> - the input matrix of double values to randomise</dd>
</dl>
</section>
</li>
</ul>
</section>
</li>
</ul>
</section>
<!-- ========= END OF CLASS DATA ========= -->
</main>
</div>
</div>
</body>
</html>
